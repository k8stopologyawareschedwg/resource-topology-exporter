---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: rte
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: rte
rules:
- apiGroups: ["topology.node.k8s.io"]
  resources: ["noderesourcetopologies"]
  verbs: ["create", "update", "get", "list"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get"]
- apiGroups: [""]
  resources: ["pods/status"]
  verbs: ["update"]
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["watch", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: rte
subjects:
- kind: ServiceAccount
  name: rte
  namespace: default
roleRef:
  kind: ClusterRole
  name: rte
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: rte-config
  namespace: default
data:
  config.yaml: |
    # key = node name, value = list of resources to be excluded.
    # use * to exclude from all nodes.
    # an example for how the exclude list should looks like
    # excludelist:
    #   node1: [cpu]
    #   node2: [memory, example/deviceA]
    #   *: [cpu]
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: resource-topology-exporter-ds
spec:
  selector:
      matchLabels:
        name: resource-topology
  template:
    metadata:
      labels:
        name: resource-topology
    spec:
      readinessGates:
        - conditionType: "PodresourcesFetched"
        - conditionType: "NodeTopologyUpdated"
      serviceAccountName: rte
      containers:
      - name: resource-topology-exporter-container
        image: ${RTE_CONTAINER_IMAGE}
        command:
        - /bin/resource-topology-exporter
        args:
          - -v=${RTE_VERBOSE}
          - --sleep-interval=${RTE_POLL_INTERVAL}
          - --sysfs=/host-sys
          - --kubelet-state-dir=/host-var/lib/kubelet
          - --kubelet-config-file=/host-var/lib/kubelet/config.yaml
          - --podresources-socket=unix:///host-var/lib/kubelet/pod-resources/kubelet.sock
          - --notify-file=/host-run/rte/notify
          - --pods-fingerprint
          - --expose-timing
          - --refresh-node-resources
        env:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: REFERENCE_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: REFERENCE_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: REFERENCE_CONTAINER_NAME
          value: shared-pool-container
        - name: METRICS_PORT
          value: "${METRICS_PORT}"
        volumeMounts:
          - name: host-sys
            mountPath: "/host-sys"
            readOnly: true
          - name: host-kubelet-state
            mountPath: "/host-var/lib/kubelet"
          - name: exclude-list-config-vol
            mountPath: "/etc/resource-topology-exporter"
          - name: host-rte-notification
            mountPath: "/host-run/rte"
        ports:
          - name: metrics-port
            containerPort: ${METRICS_PORT}
      - name: shared-pool-container
        image: gcr.io/google_containers/pause-amd64:3.0
      volumes:
      - name: host-sys
        hostPath:
          path: "/sys"
      - name: host-kubelet-state
        hostPath:
          path: "/var/lib/kubelet"
      - name: exclude-list-config-vol
        configMap:
          name: resource-topology-exporter-config
          optional: true
      - name: host-rte-notification
        hostPath:
          path: "/run/rte"
